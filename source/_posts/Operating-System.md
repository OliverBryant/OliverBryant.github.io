---
title: Operating_System
categories:
  - 考研
tags:
  - 专业课
abbrlink: 14309
mathjax: true
date: 2021-04-23 10:45:52
updated: 2021-04-23 10:45:52
permalink:
---


# 第一章：计算机系统概述

## 一、操作系统的基本概念

### 一、操作系统的概念

1. 计算机系统：自下而上分为：
    - 硬件
    - 操作系统：管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件与用户之间的媒介。
    - 应用程序
    - 用户
2. 操作系统的定义：是控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合。<font color="red">操作系统是计算机系统中最基本的系统软件</font>。

### 二、操作系统的特征

- 并发：
    - 定义：两个或多个事件在<font color="red">同一时间间隔内</font>发生。
    - 实质：在多道程序环境下，一段时间内，宏观上有多道程序在同时执行，而在每个时刻，单处理机环境下实际仅能有一道程序执行。操作系统的并发性实际是通过<font color="red">分时</font>得以实现的
    - 并行：
        - 定义：系统具有同时进行运算或操作的特性，在同一时刻能完成两种或两种以上的工作。
        - 需要相关硬件的支持，如多流水线或多处理机硬件环境
- 共享：
    - 定义：系统中的资源可供内存中多个并发执行的进程共同使用。
    - 分类：
        - 互斥共享方式：
            - 定义：在一段时间内只允许一个进程访问该资源。
            - 举例：打印机、磁带机
            - 过程：进程A需要访问某个资源<font color="orange">（称为临界资源或独占资源）</font>，先提出请求。若该资源空闲，则系统将其分配给A使用。此后有其他进程也要访问该资源，只要A没有使用完成就必须等待。仅当A访问完并释放该资源后，才允许另一个进程对该资源进行访问。
        - 同时访问方式：
            - 定义：允许在一段时间内由多个进程“同时”访问。
            - 实质：宏观上“同时”，微观上“分时”
            - 举例：磁盘设备，一些用重入码编写的文件

<font color="green"><b>并发与共享的关系：两者是操作系统两个最基本的特征，两者之间互为存在的条件</b></font>

1. 资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享问题。
2. 若系统不能对资源共享实施有效的管理，则必将影响到程序的并发执行，甚至根本无法并发执行。

- 虚拟：
    - 定义：把一个物理上的实体变为若干逻辑上的对应物。
    - 举例：
        - 虚拟处理器：
            - 定义：利用多道程序设计技术把一个物理上的CPU虚拟为多个逻辑上的CPU。
            - 原理：通过多道程序设计技术，采用让多道程序并发执行的方法，来分时使用一个处理器。
        - 虚拟存储器：
            - 定义：用户感觉到的但是实际不存在的存储器
            - 原理：采用虚拟存储器技术将一台机器的物理存储器变为虚拟存储器，以便从逻辑上扩充存储器的容量。
        - 虚拟外部设备：采用虚拟设备技术将一台物理I/O设备虚拟为多态逻辑上的I/O设备，并允许每个用户占用一台逻辑上的I/O设备。
    - 虚拟技术的分类：
        - 时分复用技术：处理器的分时共享
        - 空分复用技术：虚拟存储器
- 异步：
    - 定义：由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进。

### 三、操作系统的目的和功能

1. 操作系统作为计算机系统资源的管理者：
    - 处理机管理：
        - 进程控制
        - 进程同步
        - 进程通信
        - 死锁处理
        - 处理机调度
    - 存储器管理：
        - 内存分配与回收
        - 地址映射
        - 内存保护
        - 共享和内存扩充
    - 文件管理：
        - 文件存储空间的管理
        - 目录管理
        - 文件读写管理和保护
    - 设备管理：
        - 缓冲管理
        - 设备分配
        - 设备处理
        - 虚拟设备
2. 操作系统作为用户与计算机硬件系统之间的接口：
    - 命令接口：用户利用这些操作命令来组织和控制作业的执行
        - 联机命令接口：
            - 联机控制方式进行作业控制，适用于分时或实施系统的接口。
        - 脱机命令接口：
            - 脱机控制方式进行作业控制，适用于批处理系统，由一组作业控制命令组成。
    - 程序接口（系统调用）：
        - 编程人员可以使用它们来请求操作系统服务。
        - 由一组系统调用组成，它是操作系统为应用程序使用内核功能所提供的接口。
        - 广义指令：系统调用命令
3. 操作系统用作扩充机器：操作系统所提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器。因此，我们通常把覆盖了软件的机器称为扩充机器或虚拟机。

### 四、注

1. 库函数：高级语言中提供的与系统调用对应的函数（也有些库函数与系统调用无关），目的是隐藏”访管“指令的细节，使系统调用更为方便、抽象。库函数属于用户程序而非系统调用，是系统调用的上层。

2. 库函数与系统调用的区别和联系：

    库函数是语言或应用程序的一部分，可以运行在用户空间中。而系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中，而且许多库函数都会使用系统调用来实现功能。未使用系统调用的库函数，其执行效率通常要比系统调用的高。因为使用系统调用时，需要上下文的切换及状态的转换（由用户态转向核心态）

## 二、操作系统的发展与分类

### 一、手工操作阶段

1. 定义：用户在计算机上算题的所有工作都要人工干预。
2. 缺点：
    - 用户独占全机
    - CPU等待手工操作，CPU的利用不充分

### 二、批处理阶段

1. 单道批处理系统：
    - 定义：引入脱机输入/输出技术，并由监督程序<font color="orange">（操作系统的雏形）</font>负责控制作业的输入、输出。
    - 优点：缓解了一定程度的人机速度矛盾，资源利用率有所提升。
    - 缺点：
        - 内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序。
        - CPU有大量的时间是在空闲等待I/O完成。资源利用率依然很低。
2. 多道批处理系统：
    - 定义：每次往内存中读入多道程序，<font color="red">操作系统正式诞生，用于支持多道程序并发运行</font>。
    - 特点：
        - 多道：
        - 宏观上并行：同时进入系统的多道程序都处于运行过程中，即它们先后开始各自的运行，但都未运行完毕。
        - 微观上串行：内存中的多道程序轮流占有CPU，交替执行。
    - 优点：
        - 多道程序并发执行，共享计算机资源。
        - 资源利用率大幅提升，CPU和其他资源更能保持“忙碌”状态，系统吞吐量增大。
    - 缺点： 
        - 用户响应时间长，没有人机交互功能

### 三、分时操作系统

1. 定义：计算机以时间片为单位轮流为各个用户/作业服务，各个用户可通过终端与计算机进行交互。
2. 特点：
    - 同时性
    - 交互性
    - 独立性
    - 及时性
3. 优点：
    - 用户请求可以被即时响应，解决了人机交互问题。
    - 允许多个用户同时使用一台计算机，并且用户对计算机的操作相互独立，感受不到别人的存在。
4. 缺点：不能优先处理一些紧急任务。操作系统对各个用户/作业都是完全公平的，循环地为每个用户/作业服务一个时间片，不区分任务的紧急性。

### 四、实时操作系统

1. 定义：在实时操作系统的控制下，计算机系统接受到外部信号后及时处理，并在严格的时限内处理完事件。
2. 特点：
    - 及时性
    - 可靠性
3. 优点：能够优先响应一些紧急任务，某些紧急任务不需时间片排队。
4. 分类：
    - 硬实时系统：必须在绝对严格的规定时间内完成处理
        - 导弹控制系统
        - 自动驾驶系统
    - 软实时系统：能接受偶尔违反时间规定
        - 12306火车订票系统

### 五、网络操作系统

1. 定义：能把网络中各个计算机有机地结合起来，实现数据传送等功能，实现网络中各种资源的共享（如文件共享）和各台计算机之间的通信。

### 六、分布式操作系统

1. 定义：系统中各台计算机地位相同，任何工作都可以分布在这些计算机上，由它们并行、协同完成这个任务。
2. 特点：
    - 分布性
    - 并行性

### 七、个人计算机操作系统

- Windows
- Linux
- MacOS

## 三、操作系统的运行环境

 ### 一、操作系统的运行机制

1. 指令：CPU能识别、执行的最基本命令。（二进制）
2. 内核程序和应用程序：
    - 内核（kernel）：内核是操作系统最重要最核心的部分，也是最接近硬件的部分。由许多内核程序组成。可以运行特权指令。<font color="orange">（I/O指令、置中断指令等等）</font>
    - 应用程序：运行于操作系统之上的程序。只能运行非特权指令。
3. 内核态与用户态：
    - 内核态：
        - 定义：处于内核态时，说明此时正在运行的是内核程序，此时可以执行特权指令。
        - 别名：核心态、管态
    - 用户态：
        - 定义：处于用户态时，说明此时正在运行的是应用程序，此时只能执行非特权指令。
        - 别名：目态
    - 内核态与用户态的切换：CPU中有一个寄存器叫<font color="red">程序状态字寄存器（PSW）</font>，其中有个二进制位，1表示“内核态”，0表示“用户态”。
        - 内核态—>用户态：执行一条<font color="red">特权指令——修改PSW</font>的标志位为“用户态”
        - 用户态—>内核态：由“中断”引发，硬件自动完成变态过程，触发中断信号意味着操作系统将强行夺回CPU的使用权。
4. 内核内容：
    - 时钟管理：
        - 计时
        - 时钟中断：实现进程的切换
    - 中断机制：
        - 目的：提高多道程序运行环境中CPU的利用率<font color="orange">（主要是针对外部设备）</font>
        - 作用：保护和恢复中断现场的信息，转移控制权到相关的处理程序
    - 原语：
        - 定义：具有以下特点的程序称为原语（Atomic Operation）
        - 特点：
            - 处于操作系统的最底层，是最接近硬件的部分
            - 这些程序的运行具有原子性，其操作只能是一气呵成。<font color="orange">（主要从系统安全性和便于管理考虑）</font>
            - 这些程序的运行时间都较短，而且调用频繁。
        - 定义方法：关闭中断，让其所有动作都不可分割地完成后再打开中断。
    - 系统控制的数据结构及处理：
        - 进程管理：进程状态管理、进程调度和分配、创建与撤销进程控制块
        - 存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序
        - 设备管理：缓冲区管理、设备分配和回收

### 二、中断和异常

1. 中断的概念：在CPU上会运行两种程序，一种是<font color="red">应用程序</font>，一种是<font color="red">操作系统内核程序</font>。在合适的情况下，操作系统内核会把CPU的使用权主动让给应用程序。而“中断”是让操作系统内核夺回CPU使用权的唯一途径。
2. 中断的分类：
    - 内中断（异常）：
        - 定义：与当前执行的指令有关，中断信号来源于CPU内部
        - 类型：
            - 陷阱、陷入（trap）：由陷入指令引发，是应用程序故意引发的
            - 故障（fault）：由错误条件引起的，可能被内核程序修复。内核程序修复故障后会把CPU使用权还给应用程序，让他继续执行下去。<font color="orange">（缺页故障）</font>
            - 终止（abort）：由致命错误引起，内核程序无法修复该错误，因此一般不再将CPU使用权还给引发终止的应用程序，而是直接终止该应用程序。<font color="orange">（整数除0、非法使用特权指令）</font>
    - 外中断（中断）：
        - 定义：与当前执行的指令无关，中断信号来自CPU外部
        - 类型：
            - 时钟中断
            - I/O中断请求
3. 中断处理的过程：
    - 关中断：CPU响应中断后，首先要保护程序的现场状态，在保护现场的过程中，CPU不应响应更高级中断源的中断请求。否则，若现场保存不完整，中断服务程序结束后，不能正确地恢复并继续执行现行程序。
    - 保存断点：为保证中断服务程序执行完毕后能正确地回到原来的程序，必须将原来的程序的断点（程序计数器PC）保存起来。
    - 中断服务程序寻址：取出中断服务程序的入口地址送入程序计数器PC。
    - 保存现场和屏蔽字：进入中断服务程序后，首先要保存现场，现场信息一般是指程序状态字寄存器PSWR和某些通用寄存器的内容。
    - 开中断：允许更高级中断请求得到响应。
    - 执行中断服务程序：中断请求的目的。
    - 关中断：保证在恢复现场和屏蔽字时不被中断。
    - 恢复现场和屏蔽字：将现场和屏蔽字恢复到原来的状态。
    - 开中断，中断返回：中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。

### 三、系统调用

1. 定义：用户在程序中调用操作系统所提供的一些子功能，可视为特殊的公共子程序，<font color="red">应用程序可以通过系统调用来请求获得操作系统内核的服务</font>。

2. 何时用：凡是与共享资源有关的操作（存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统内核提出服务请求。

3. 目的：保证系统的稳定性和安全性。

4. 分类：

    - 设备管理：完成设备的请求/释放/启动等功能
    - 文件管理：完成文件的读/写/创建/删除等功能
    - 进程控制：完成进程的创建/撤销/阻塞/唤醒等功能
    - 进程通信：完成进程之间的消息传递/信号传递等功能
    - 内存管理：完成内存的分配/回收等功能

5. 系统调用的过程：

    - 传递系统调用参数
    - 执行陷入指令<font color="red">（用户态）</font>
    - 运行相应的内请求核程序处理系统调用<font color="red">（核心态）</font>
    - 返回应用程序

    注：

    1. 陷入指令是在用户态执行的，执行陷入指令后引发一个内中断，使CPU进入核心态
    2. 发出系统调用请求是在用户态，而对系统调用的相应处理在核心态下进行

## 四、操作系统的体系结构

1. 大内核：
    - 定义：将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而应用提高性能的系统服务。
    - 优点：高性能
    - 缺点：内核代码庞大，结构混乱，难以维护
    - 典型系统：Linux、Unix
2. 微内核：
    - 定义：将内核中最基本的功能保留在内核，将那些不需要在核心态执行的功能移到用户态执行。
    - 优点：内核功能少，结构清晰，方便维护
    - 缺点：需要频繁地在核心态和用户态之间切换，性能低
    - 典型系统：Windows NT

# 第二章：进程管理

## 一、进程和线程

### 一、进程的概念和特征

1. 定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。

2. 组成：

    - 进程控制块（PCB）：进程存在的唯一标志，当进程被创建时，操作系统为其创建PCB，当进程结束时，会回收PCB。<font color="red">操作系统对进程进行管理工作所需的信息都在PCB中</font>
        - 进程描述信息：
            - 进程标识符PID
            - 用户标识符UID
        - 进程控制和管理信息：
            - CPU、磁盘、网络流量使用情况统计...
            - 进程当前状态
        - 资源分配清单：
            - 正在使用哪些文件
            - 正在使用哪些内存区域
            - 正在使用哪些I/O设备
        - 处理机相关信息：
            - 如PSW、PC等各种寄存器的值<font color="orange">（用于实现进程切换）</font>
    - 程序段：程序的代码<font color="orange">（指令序列）</font>
    - 数据段：运行过程中产生的各种数据

    <font color="green">PCB是给操作系统用的，程序段、数据段是给进程自己用的。</font>

3. 特征：

    - 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的。<font color="red">动态性是进程最基本的特征</font>
    - 并发性：内存中有多个进程实体，各进程可并发执行。
    - 独立性：进程是能独立运行、独立获得资源、独立接受调度的基本单位。
    - 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制”来解决异步性。
    - 结构性：每个进程都会配置一个PCB。结构上看，进程由程序段、数据段和PCB组成。

### 二、进程的状态与转换

1. 五种状态：

    - 创建态（New）：
        - 定义：进程正在被创建
        - 步骤：
            - 申请一个空白的PCB
            - 向PCB中填写一些控制和管理进程的信息
            - 由系统为该进程分配运行时所必须的资源
            - 把该进程转入就绪态
    - <font color=green>就绪态</font>（Ready）：
        - 定义：进程获得了除处理机外的一切所需资源。一旦得到处理机，便可立即运行。
        - 注：系统中处于就绪态的进程可以有多个，通常把它们排成一个队列，称为就绪队列。
    - <font color=green>运行态</font>（Running）：
        - 定义：进程正在处理机上运行，CPU会执行该进程对应的程序<font color="orange">（执行指令序列）</font>。
        - 注：在单核CPU环境下，每个时刻最多有一个进程处于运行态。
    - <font color=green>阻塞态</font>（Waiting/Blocked）：
        - 定义：进程正在等待某一事件而暂停运行。
        - 注：即使处理机空闲，该进程也不能运行。
    - 终止态（Terminated）：
        - 定义：进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。
        - 步骤：
            - 将该进程置为终止态
            - 进程下CPU，并回收内存空间等资源
            - 回收该进程的PCB

    <font color="green">上述标绿的为3种基本状态</font>

2. 3种基本状态的转换：

    - 就绪态——>运行态：处于就绪态的进程被调度后，获得处理机资源
    - 运行态——>就绪态：
        - 处于运行态的进程在时间片用完后，不得不让出处理机
        - 在可剥夺的操作系统中，被更高优先级的进程抢占
    - 运行态——>阻塞态：
        - 进程请求某一资源的使用和分配或等待某一事件的发生
        - 注：此种转换是进程自身作出的<font color="red">主动行为</font>。
    - 阻塞态——>就绪态：
        - 进程等待的事件到来
        - 注：此种转换是<font color="red">被动行为</font>，需要其他相关进程的协助。

    ![进程状态](https://oliver-picture.oss-cn-beijing.aliyuncs.com/img/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81.png)

### 三、进程控制

1. 功能：对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。

2. 进程控制的实现：原语

    - 原语的执行具有原子性，期间不允许被中断。
    - 通过“关中断指令”和“开中断指令”两条<font color="red">特权指令</font>实现。
    - CPU在执行关中断指令后，不再例行检查中断信号，直到执行开中断指令之后才会恢复检查。

3. 进程的创建：

    - 创建原语：操作系统创建一个进程时使用的原语，会将进程从创建态转入就绪态
        - 为新进程分配一个唯一的进程标识号，并申请空白PCB
        - 为新进程分配所需资源。<font color="red">若资源不足，不会创建失败，而是进入阻塞态</font>。
        - 初始化PCB
        - 将PCB插入就绪队列
    - 引起进程创建的事件：
        - 用户登录：分时系统中，用户登录成功，系统会为其建立一个新的进程
        - 作业调度：多道批处理系统中，有新的作业放入内存时，会为其建立一个新的进程
        - 提供服务：用户向操作系统提出某些请求时，会新建一个进程处理该请求
        - 应用请求：由用户进程主动请求创建一个子进程

4. 进程的终止：

    - 撤销原语：操作系统终止一个进程时使用的原语，会将进程从就绪态/阻塞态/运行态变为终止态。
        - 从PCB集合中找到终止进程的PCB，读出该进程的状态
        - 若该进程正在运行，立即剥夺CPU，将CPU分配给其他进程
        - 终止其所有子进程
        - 将该进程所用由的全部资源，归还给父进程或操作系统
        - 删除PCB
    - 引起进程终止的事件：
        - 正常结束
        - 异常结束
        - 外界干预

5. 进程的阻塞

    - 阻塞原语：将进程从运行态变为阻塞态
        - 找到要阻塞的进程对应的PCB
        - 保护进程现场，将PCB状态信息设置为“阻塞态”，暂时停止进程运行
        - 将PCB插入相应事件的等待队列
    - 引起进程阻塞的事件：
        - 需要等待系统分配某种资源
        - 需要等待相互合作的其他进程完成工作

6. 进程的唤醒：

    - 唤醒原语：将进程从阻塞态转为就绪态
        - 在事件等待队列中找到PCB
        - 将PCB从等待队列中移除，设置进程为就绪态
        - 将PCB插入就绪队列，等待被调度
    - 引起进程唤醒的事件：等待的事件发生

    <font color="green">注：因何事阻塞，就应由何事唤醒，故阻塞原语唤醒原语必须成对使用。</font>

7. 进程的切换：

    - 切换原语：将进程从运行态变为就绪态，或从就绪态变为运行态
        - 将运行环境信息存入PCB
        - PCB移入相应队列
        - 选择另一个进程执行，并更新其PCB
        - 更新内存管理的数据结构
        - 恢复处理机上下文
    - 引起进程切换的事件：
        - 当前进程时间片到
        - 有更高优先级的进程到达
        - 当前进程主动阻塞
        - 当前进程终止

### 四、进程通信

1. 进程通信的概念：进程之间的信息交换。
2. 共享存储：
    - 定义：在通信的进程之间存在一块可以直接访问的共享空间<font color="orange">（由操作系统提供）</font>，<font color="red">两个进程对共享空间的访问必须互斥<font color="orange">（互斥访问通过操作系统提供的工具实现）</font></font>
    - 基于数据结构的共享：速度慢，限制多，低级通信方式
    - 基于存储区的共享：
        - 在内存中画出一块共享存储区。
        - 速度快，高级通信方式
3. 管道通信：
    - 定义：管道（pipe）是指用于连接读写进程的一个共享文件，其实就是在内存中开辟的一个大小固定的缓冲区。
    - 管道只能采用<font color="red">半双工通信</font>，某一时间段只能实现单向的传输。如果要实现双向同时通信，则需设置两个管道。
    - 各进程要互斥地访问管道
    - 数据以<font color="red">字符流</font>的形式写入管道，当管道写满时，写进程的write()系统调用被阻塞，等待度进程将数据取走；当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。
    - 如果没写满，就不允许读；如果没读空，就不允许写。
    - 数据一旦被读出，就从管道中被抛弃，这意味着<font color="red">读进程最多只能有一个</font>。
4. 消息传递：
    - 定义：进程见的数据交换以<font color="red">格式化的消息（Message）</font>为单位，通过操作系统提供的”发送消息/接受消息“两个原语进行数据交换
    - 消息：
        - 消息头：包括发送进程ID、接收进程ID、消息类型、消息长度等格式化的信息
        - 消息体
    - 类型：
        - 直接通信方式：消息直接挂到接收进程的消息缓冲队列上
        - 简介通信方式：消息要先发送到中间实体<font color="orange">（信箱）</font>中

### 五、线程概念和多线程模型

1. 线程的概念：”轻量级进程“，是一个基本的CPU执行单元，也是程序执行流的最小单位。

2. 与进程的比较：

    |   变化   |                      进程                      |                             线程                             |
    | :------: | :--------------------------------------------: | :----------------------------------------------------------: |
    |   调度   |       进程时用由资源和独立调度的基本单位       |      线程是独立调度的基本单位，进程是资源分配的基本单位      |
    |  并发性  |                 只能进程间并发                 |                既能进程间并发，也可线程间并发                |
    | 系统开销 | 进程间并发，需要切换进程的运行环境，系统开销大 | 线程间并发，若为统一进程内线程切换，则不需切换进程环境，系统开销小 |

3. 线程的属性：

    - 线程是处理机调度的单位
    - 多CPU计算机中，每个线程可占用不同的CPU
    - 每个线程都有一个线程ID、线程控制块TCB
    - 线程也有就绪、阻塞、运行三种基本状态
    - 线程几乎不拥有系统资源
    - 统一进程的不同线程间共享进程的资源
    - 由于共享内存地址空间，统一进程中的线程间通信甚至无需系统干预
    - 同一进程中线程切换，不会引起进程切换，系统开销很小
    - 不同进程中的线程切换，会引起进程切换，系统开销较大

4. 线程的实现方式：

    - 用户级线程：
        - 用户级线程由应用程序通过线程库实现，所有的线程管理工作都由应用程序负责
        - 线程切换在用户态下即可完成，无需操作系统干预
        - 在用户看来，是有多个线程。在操作系统内核看来，只有进程。
        - 优点：线程切换不需要切换到核心态，线程管理的系统开销小，效率高
        - 缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并行运行。
    - 内核级线程：
        - 内核级线程的管理工作由操作系统内核完成。
        - 线程调度、切换等工作都由内核负责，因此内核级线程的切换必然需要在核心态下才能完成。
        - 操作系统会为每个内核级线程建立相应的TCB，通过TCB对线程进行管理。
        - 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理机上并行执行。
        - 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大。

5. 多线程模型：

    - 一对一模型：
        - 定义：一个用户级线程映射到一个内核级线程，每个用户进程有与用户级线程同数量的内核级线程。
        - 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理机上并行执行。
        - 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大。
    - 多对一模型：
        - 定义：多个用户级线程映射到一个内核级线程，即一个进程只被分配一个内核级线程。
        - 优点：线程切换不需要切换到核心态，线程管理的系统开销小，效率高
        - 缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并行运行。
    - 多对多模型：
        - 定义：n个用户级线程映射到m个内核级线程<font color="red">（n>=m）</font>。每个用户进程对应m个内核级线程。
        - 特点：克服了多对一模型并发度不高的特点，也克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

## 二、处理机调度

### 一、调度的概念

1. 定义：对处理机进行分配，即从就绪队列中按照一定的算法（公平、高效）选择一个进程并将处理机分配给它运行，以实现进程并发地运行。

2. 调度的层次：
    - 高级调度（作业调度）：
        - 主要任务：按一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。
        - 特点：
            - 每个作业只调入一次，调出一次。调入时建立PCB，调出时撤销PCB。
            - 执行频率较低，通常是几分钟一次
    - 中级调度（内存调度）：
        - 主要任务：内存不够时，将某些进程的数据调出外存。等内存空闲或者进程需要运行时再重新调入内存。
        - 特点：
            - 一个进程可能会被多次调出、调入内存
            - 执行频率比高级调度高
        - 暂时调到外存等待的进程状态为<font color=red>挂起状态</font>。被挂起的进程PCB会被组织成<font color=red>挂起队列</font>。
    - 低级调度（进程调度）：
        - 主要任务：按照某种策略从就绪队列中选取一个进程，将处理机分配给它。
        - 特点：
            - 进程调度是操作系统中<font color=red>最基本的一种调度</font>，在一般的操作系统中必须配置进程调度。
            - 执行频率很高，一般几十毫秒一次
    
3. 进程的挂起态和七状态模型：

    - 暂时调到外存等待的进程状态为挂起状态（挂起态，Suspend）
    - 挂起态又可进一步细分为就绪挂起、阻塞挂起两种状态。
    - 七状态模型：![七状态模型](https://oliver-picture.oss-cn-beijing.aliyuncs.com/img/%E4%B8%83%E7%8A%B6%E6%80%81%E6%A8%A1%E5%9E%8B.png)
    - 挂起和阻塞都是暂时不能获得CPU服务，但是挂起态是将进程映像调到外存去了，而阻塞态进程映像还在内存中

4. 三种调度的联系与对比：

    |          |                           要做什么                           | 调度发生位置 | 发生频率 |  对进程状态的影响  |
    | :------: | :----------------------------------------------------------: | :----------: | :------: | :----------------: |
    | 高级调度 | 按照某种规则，从后备队列中选择合适的作业将其调入内存，并为其创建进程 |  外存—>内存  |   最低   | 无—>创建态—>就绪态 |
    | 中级调度 |   按照某种规则，从挂起队列中选择合适的进程将其数据调回内存   |  外存—>内存  |   中等   |   挂起态—>就绪态   |
    | 低级调度 |     按照某种规则，从就绪队列中选择一个进程为其分配处理机     |  内存—>CPU   |   最高   |   就绪态—>运行态   |


### 二、进程调度的时机、切换和过程

1. 时机：
    - 需要进行进程调度与切换的情况：
        - 当前运行的进程主动放弃处理机：
            - 进程正常终止
            - 运行过程中发生异常而终止
            - 进程主动请求阻塞
        - 当前运行的进程被动放弃处理机：
            - 分给进程的时间片用完
            - 有更紧急的事需要处理
            - 有更高优先级的进程进入就绪队列
    - 不能进行进程调度与切换的情况：
        - 在处理中断的过程中：中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换。
        - 进程在操作系统内核程序临界区中
          - 临界资源：一个时间段内只允许一个进程使用的资源。各进程需要互斥地访问临界资源。
          - 临界区：访问临界资源的那段代码。
          - 内核临界区：用来访问某种内核数据结构
        - 在原子操作过程中（原语）：原子操作不可中断
2. 方式：
    - 非剥夺调度方式（非抢占方式）：
      - 定义：只允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。
      - 优点：实现简单，系统开销小
      - 缺点：无法及时处理紧急任务
    - 剥夺调度方式（抢占方式）：
      - 定义：当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要更紧迫的进程。
      - 优点：可以优先处理更紧急的进程，也可实现让各进程按时间片轮流执行的功能（时钟中断）
3. 进程的切换与过程：
    - 狭义的进程调度：从就绪队列中选中一个要运行的进程。
    - 进程切换：让一个进程让出处理机，由另一个进程占用处理机。 
      - 步骤：
        - 对原来运行进程各种数据的保存
        - 对新的进程各种数据的恢复
      - 进程切换是有代价的，如果过于频繁进行进程调度、切换，必然会使整个系统的效率降低。
    - 广义的进程调度：包含选择和进程切换两个步骤。

### 三、调度算法的评价指标

1. CPU利用率：

   - 定义：CPU“忙碌”的时间占总时间的比例。

   - 公式：
     $$
     利用率=\frac{忙碌的时间}{总时间}
     $$

2. 系统吞吐量：

   - 定义：单位时间内完成作业的数量

   - 公式：
     $$
     系统吞吐量=\frac{总共完成了多少道作业}{总共花了多少时间}
     $$

3. 周转时间：

   - 定义：从作业被提交给系统开始，到作业完成为止这段时间间隔。

   - 包括：

     - 作业在外存后备队列上等待作业调度（高级调度）的时间
     - 进程在就绪队列上等待进程调度（低级调度）的时间
     - 进程在CPU上执行的时间
     - 进程等待I/O操作完成的时间

   - 公式：

     - 周转时间：
       $$
       周转时间=作业完成时间-作业提交时间
       $$

     - 平均周转时间：
       $$
       平均周转时间=\frac{各作业周转时间之和}{作业数}
       $$

     - 带权周转时间：
       $$
       带权周转时间=\frac{作业周转时间}{作业实际运行的时间}=\frac{作业完成时间-作业提交时间}{作业实际运行的时间}
       $$

     - 平均带权周转时间：
       $$
       平均带权周转时间=\frac{各作业带权周转时间之和}{作业数}
       $$

4. 等待时间：

   - 定义：进程/作业等待处理机状态时间之和，等待时间越长，用户满意度越低。
     - 进程：等待时间就是指进程建立后等待被服务的时间之和，在等待I/O完成的期间其实进程也是在被服务的，所以不计入等待时间。
     - 作业：不仅要考虑建立进程后的等待时间，还要加上作业在外存后备队列中等待的时间

5. 响应时间：

   - 定义：用户从提交请求到首次产生响应所用的时间。

### 四、调度算法

1. 先来先服务（FCFS）：
   - 算法思想：主要从“公平”的角度考虑
   - 算法规则：按照作业/进程到达的先后顺序进行服务
   - 用于作业/进程调度：用于作业调度时，考虑的是哪个作业先到达后备队列；用于进程调度时，考虑的是哪个进程先到达就绪队列。
   - 是否可抢占：非抢占式的算法
   - 优点：公平、算法实现简单
   - 缺点：排在长作业（进程）后面的短作业需要等待很长的时间，带权周转时间很大，对短作业来说用户体验不好
   - 是否会导致饥饿：不会
   
2. 短作业优先（SJF）：
   - 算法思想：追求最少的平均等待时间，最少的平均周转时间、最少的平均带权周转时间
   - 算法规则：最短的作业/进程优先得到服务（所谓“最短”，是指要求服务时间最短）
   - 用于作业/进程调度：既可用于作业调度，也可用于进程调度。<font color=orange>（用于进程调度时称为“短进程优先算法”，SPF）</font>
   - 是否可抢占：SJF和SPF是非抢占式的算法。但是也有可抢占式的版本——最短剩余时间优先算法（SRTN）
   - 优点：“最短的”平均等待时间、平均周转时间
   - 缺点：
     - 不公平，对短作业有利，对长作业不利。
     - 可能产生饥饿现象
     - 作业/进程的运行时间是由用户提供的，并不一定真实，不一定能做到真正的短作业优先。
   - 是否会导致饥饿：会。如果源源不断地有短作业/进程到来，可能使长作业/进程长时间得不到服务，产生“饥饿”现象。如果一直得不到服务，则称为“饿死”。
   
3. 高响应比优先（HRRN）：

   - 算法思想：综合考虑作业/进程的等待时间和要求服务的时间

   - 算法规则：在每次调度时先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务。
     $$
     响应比=\frac{等待时间+要求服务时间}{要求服务时间}
     $$

   - 用于作业/进程调度：既可用于作业调度，也可用于进程调度

   - 是否可抢占：非抢占式的算法。只有当前运行的作业/进程主动放弃处理机时，才需要调度，才需要计算响应比。

   - 优点：

     - 综合考虑了等待时间和运行时间（要求服务时间）
     - 等待时间相同时，要求服务时间短的优先（SJF的优点）
     - 要求服务时间相同时，等待时间长的优先（FCFS的优点）
     - 对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。

   - 是否会导致饥饿：不会

   <font color=green>注：以上三种算法主要关心对用户的公平性、平均周转时间、平均等待时间等评价系统整体性能的指标，但是交互性很差。因此这三种算法一般适合早期的批处理系统。</font>

4. 时间片轮转（RR）：

   - 算法思想：公平地、轮流地为各个进程服务，让每个进程在一定时间间隔内都可以得到响应。
   - 算法规则：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片（如100ms）。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾重新排队。
   - 用于作业/进程调度：用于进程调度。<font color=orange>（只有作业放入内存建立了相应的进程后，才能被分配处理机时间片）</font>
   - 是否可抢占：若进程未能在时间片内运行完，将被强行剥夺处理机使用权，因此时间片轮转调度算法属于抢占式的算法。<font color=orange>由时钟装置发出时钟中断来通知CPU时间片已到</font>。
   - 优点：
     - 公平
     - 响应快，适合于分时操作系统
   - 缺点：
     - 由于高频率的进程切换，因此有一定开销
     - 不区分任务的紧急程度
   - 是否会导致饥饿：不会
   - 补充：
     - 若时间片太大，则几乎变成FCFS
     - 若时间片太小，则大部分时间用于进程切换，浪费资源

5. 优先级调度：

   - 算法思想：随着计算机的发展，特别是实时操作系统的出现，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序
   - 算法规则：调度时选择优先级最高的作业/进程
   - 用于作业/进程调度：既可用于作业调度，也可用于进程调度。
   - 是否可抢占：抢占式、非抢占式都有
   - 优点：用优先级区分紧急程度、重要程度，适用于实时操作系统。可灵活地调整对各种作业/进程的偏好程度。
   - 缺点：若源源不断地有高优先级进程到来，则可能导致饥饿。
   - 是否会导致饥饿：会
   - 补充：
     - 就绪队列未必只有一个，可以按照不同优先级来组织；也可把优先级高的进程排在更靠近队头的位置。
     - 优先级的分类：
       - 静态优先级：创建进程时确定，之后就一直不变
       - 动态优先级：创建进程时有一个初始值，之后会根据情况动态地调整优先级
     - 系统进程优先级高于用户进程
     - 前台进程优先级高于后台进程
     - 操作系统更偏好<font color=red>I/O型进程</font>
     - 动态优先级调整原则：
       - 如果某进程在就绪队列等待了很长时间，则可以适当提升其优先级
       - 如果某进程占用处理机运行了很长时间，则可以适当降低其优先级
       - 如果发现一个进程频繁地进行I/O操作，则可以适当提升其优先级
   
6. 多级反馈队列调度：

   - 算法思想：对其他调度算法的折中权衡
   - 算法规则：
     - 设置多个就绪队列，各队列优先级从高到低，时间片从小到大
     - 新进程到达时先进若第一级队列，按FCFS原则排队等待被分配时间片；若使用完时间片进程还未结束，则进程进入下一级队列队尾。若此时已经在最下级队列，则重新放回该队列队尾。
     - 只有第k级队列为空时，才会为k+1级队头的进程分配时间片
   - 用于作业/进程调度：用于进程调度
   - 是否可抢占：抢占式的算法。<font color=orange>在k级队列的进程运行过程中，若更上级的队列中进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回k级队列队尾</font>。
   - 优点：对各类型进程相对公平（FCFS的优点）；每个新到达的进程都可以很快得到响应（RR的优点）；短进程只用较少的时间就可完成（SPF的优点）；不必实现估计进程的运行时间（避免用户作假）；可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、I/O密集型进程。
   - 是否会导致饥饿：会

## 三、进程同步

### 一、进程同步的基本概念

1. 同步：

   - 定义：亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。

2. 临界资源：

   - 定义：一次仅允许一个进程使用的资源称为临界资源。

   - 临界资源的访问过程：

     - 进入区：为了进入临界区使用临界资源，进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志<font color=orange>（上锁）</font>，以阻止其他进程同时进入临界区。
     - 临界区：进程中访问临界资源的那段代码，也称临界段。
     - 退出区：将正在访问临界区的标志清楚<font color=orange>（解锁）</font>。
     - 剩余区：代码中的其余部分。

     ```c
     do {
     	entry section;           //进入区
     	critical section;        //临界区
     	exit section;            //退出区
     	remainder section;       //剩余区
     } while(true)
     ```

3. 互斥：

   - 定义：亦称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界进程。
   - 同步机制应遵循的规则：
     - 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
     - 忙则等待：当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
     - 有限等待：对请求访问的进程，应保证能在有限时间内进入临界区。
     - 让权等待：当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

### 二、实现临界区互斥的基本方法

1. 软件实现方法：

   - 单标志法：

     - 算法思想：两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程。也就是说，每个进程进入临界区的权限只能被另一个进程赋予。

     - 实现：

       ```c
       int turn=0; //turn表示当前允许进入临界区的进程号
       
       //P0进程：
       while(turn!=0);
       critical section;
       turn = 1;
       remainder section;
       
       //P1进程：
       while(turn!=1);
       critical section;
       turn = 0;
       remainder section;
       ```

     - 优点：同一时刻最多只允许一个进程访问临界区

     - 缺点：违反“空闲让进”原则

   - 双标志先检查法：

     - 算法思想：设置一个布尔型数组flag[]，数组中各个元素用来标记各进程想进入临界区的意愿。每个进程在进入临界区之前先检查当前没有别的进程想进入临界区，如果没有，则把自身对应的标志flag[i]设为true，之后开始访问临界区。

     - 实现：

       ```c
       bool flag[2];          //表示进入临界区意愿的数组
       flag[0] = false;
       flag[1] = false;       //刚开始设置为两个进程都不想进入临界区
       
       //P0进程：
       while(flag[1]);        //如果此时P0想进入临界区，P1就一直等待
       flag[0] = true;        //标记为P0进程想要进入临界区
       critical section;      //访问临界区
       flag[0] = false;       //访问完临界区，修改标记为P0不想使用临界区
       remainder section;
       
       //P1进程：
       while(flag[0]);
       flag[1] = true;
       critical section;
       flag[1] = false;
       remainder section;
       ```

     - 优点：解决了“忙则等待”的问题

     - 缺点：违背了“空闲让进”和“有限等待”原则，会因各进程都长期无法访问临界资源而产生“饥饿”现象

   - Peterson算法：

     - 算法思想：结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试先让对方使用。

     - 实现：

       ```c
       bool flag[2];
       int turn = 0;
       
       //P0进程：
       flag[0] = true;                   //标记为P0进程想要进入临界区
       turn = 1;                         //表示可以先让对方使用
       while(flag[1] && turn==1);
       critical section;                 //访问临界区
       flag[0] = false;                  //访问完临界区，修改标记为P0不想使用临界区
       remainder section;
       
       //P1进程：
       flag[1] = true;
       turn = 0;
       while(flag[0] && turn==0);
       critical section;
       flag[1] = false;
       remainder section;
       ```

     - 优点：解决了“空闲让进”、“忙则等待”、“有限等待”三个原则

     - 缺点：违背了“让权等待”原则

2. 硬件实现方法：

   - 中断屏蔽方法：

     - 思想：利用“开/关中断指令”实现。

     - 实现：

       ```c
       关中断;
       临界区;
       开中断;
       ```

     - 优点：简单、高效

     - 缺点：

       - 不适用于多处理机
       - 只适用于操作系统内核进程，不适用于用户进程

   - TestAndSet指令

     - 思想：通过硬件实现，这条指令时原子操作，即执行该代码时不允许被中断。

     - 功能：读出指定标志后把该标志设为true

     - 实现：

       ```c
       bool TestAndSet (bool *lock){    //布尔型共享变量lock表示当前临界区是否被加锁，true表示已加锁，false表示未加锁
           bool old;
           old = *lock;                 //old用来存放lock原来的值
           *lock = true;                //无论之前是否已加锁，都将lock设为true
           return old;                  //返回lock原来的值
       }
       
       //TSL指令实现互斥的算法逻辑
       while(TestAndSet (&lock));       //上锁并检查
       临界区代码段;
       lock = false;                    //解锁
       剩余区代码段;
       ```

     - 优点：

       - 实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞
       - 适用于多处理机环境

     - 缺点：不满足“让权等待”原则

   - Swap指令（Exchang、XCHG）

     - 思想：通过硬件实现，这条指令时原子操作，即执行该代码时不允许被中断。

     - 功能：交换两个字的内容

     - 实现：

       ```c
       bool Swap (bool *a,bool *b){
           temp = *a;
           *a = *b;
           *b = temp;
       }
       
       //TSL指令实现互斥的算法逻辑
       bool old = true;
       while(old == true)
           Swap (&lock,&old);
       临界区代码段;
       lock = false;
       剩余区代码段;
       ```

     - 优点：

       - 实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞
       - 适用于多处理机环境

     - 缺点：不满足“让权等待”原则

### 三、信号量机制

1. 信号量：一个变量，可以是一个整数，也可以是更复杂的记录型变量。可以用一个信号量来表示系统中某种资源的数量。

2. 原语：一种特殊的程序段，只能一气呵成，不可被中断。原语是由关中断/开中断指令实现的。

3. P、V操作：wait(S)和signal(S)原语的简称。

4. 整型信号量：

   - 定义：用一个整数型的变量作为信号量，用来表示系统中某种资源的数量。

   - 实现：

     ```c
     int S = 1;                //初始化整形变量S，表示当前系统中可用的打印机资源数
     
     void wait (int S){        //wait原语，相当于“进入区”
         while (S<=0);         //如果资源数不够，就一直循环等待
         S = S-1;              //如果资源数够，则占用一个资源
     }
     
     void signal (int S){      //signal原语，相当于“退出区”
         S = S+1;              //使用完资源后，在退出区释放资源
     }
     ```

   - 优点：“检查”和“上锁”一气呵成，避免了并发、异步导致的问题

   - 缺点：不满足“让权等待”原则，会发生“忙等”

5. 记录型信号量：

   - 定义：

     ```c
     typedef struct {
         int value;
         struct process *L;
     } semaphore;
     ```

   - 实现：

     ```c
     void wait (semaphore S) {
         S.value--;
         if(S.value < 0){             //如果资源数不够
             block(S.L);              //使用block原语使进程进入阻塞态，并挂到信号量S的等待队列中
         }
     }
     
     void signal (semaphore S) {
         S.value++;
         if(S.value<=0){              //释放资源后，若还有别的进程在等待这种资源
             wakeup(S.L);             //使用wakeup原语唤醒等待队列中的一个进程，使其从阻塞态变为运行态
         }
     }
     ```

   - 优点：实现了“让权等待”原则
   
6. 信号量机制实现进程互斥：

   - 概念：

     - 设置互斥信号量mutex，初值为1
     - 在进入区P(mutex)──申请资源
     - 在退出区V(mutex)──释放资源

   - 实现：

     ```c
     semaphore mutex = 1;    //初始化信号量
     
     P1(){
         ...
         P(mutex);           //设置临界资源前需要加锁
         临界区代码;
         V(mutex);           //使用临界资源后需要解锁
         ...
     }
     
     P2(){
         ...
         P(mutex);
         临界区代码;
         V(mutex);
         ...
     }
     ```

   - 注：

     - 对不同的临界资源需要设置不同的互斥信号量
     - P、V操作必须成对出现。
       - 缺少P(mutex)不能保证临界资源的互斥访问
       - 缺少V(mutex)会导致资源永不被释放，等待进程永不被唤醒

7. 信号量机制实现进程同步：

   - 概念：

     - 设置同步信号量S，初始为0
     - 在“前操作”之后执行V(S)
     - 在”后操作“之后执行P(S)

   - 实现：保证代码2在代码4之前执行

     ```c
     semaphore S=0
     
     P1(){
         代码1;
         代码2;
         V(S);
         代码3;
     }
     
     P2(){
         P(S);
         代码4;
         代码5;
         代码6;
     }
     ```

8. 信号量机制实现前驱关系：

   - 方法：

     - 为每一对前驱关系各设置一个同步信号量
     - 在“前操作”之后对相应的同步信号量执行V操作
     - 在”后操作“之后对相应的同步信号量执行P操作

   - 例图：![前驱](https://oliver-picture.oss-cn-beijing.aliyuncs.com/OS/qq.png)

   - 实现：

     ```{
     semaphore a1=a2=b1=b2=c=d=e=0;
     S1(){
     	...;
     	V(a1);
     	V(a2);
     }
     S2(){
     	P(a1);
     	...;
     	V(b1);
     	V(b2);
     }
     S3(){
     	P(a2);
     	...;
     	V(e);
     }
     S4(){
     	P(b1);
     	...;
     	V(c);
     }
     S5(){
     	P(b2);
     	...;
     	V(d);
     }
     S6(){
     	P(c);
     	P(d);
     	P(e);
     	...;
     }
     ```


### 四、生产者消费者问题

1. 问题描述：

   - 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。
   - 生产者、消费者共享一个初始为空、大小为n的缓冲区
   - 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待
   - 只要缓冲区不空时，消费者才能从中取出产品，否则必须等待
   - 缓冲区是临界资源，各进程必须互斥地访问

2. 分析步骤：

   - 关系分析：找出题目中描述的各个进程，分析他们之间的同步、互斥关系。
   - 整理思路：根据各进程的操作流程确定P、V操作的大致顺序。
   - 设置信号量：根据题目条件确定信号量初值。<font color=orange>（互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少）</font>

3. 实现：

   ```c
   semaphore mutex = 1;               //互斥信号量，实现对缓冲区的互斥访问
   semaphore empty = n;               //同步信号量，表示空闲缓冲区的数量
   semaphore full = 0;                //同步信号量，表示产品的数量，也即非空缓冲区的数量
   
   producer(){
       while(1){
           生产一个产品;
           P(empty);
           P(mutex);
           把产品放入缓冲区;
           V(mutex);
           V(full);
       }
   }
   
   consumer(){
       while(1){
           P(full);
           P(mutex);
           从缓冲区取出一个产品;
           V(mutex);
           V(empty);
           使用产品;
       }
   }
   ```

4. 注：

   - 实现互斥的P操作一定要在实现同步的P操作之后
   - V操作可以互换位置
   - 使用产品和生产产品也可以放入互斥之间，只是会使得临界区代码冗杂，导致上锁时间加长

### 五、多生产者多消费者问题

1. 问题描述：桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。只有盘子空时，爸爸或妈妈才可向盘子中放一个水果。仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。

2. 实现：

   ```c
   semaphore mutex = 1;
   semaphore apple = 0;
   semaphore orange = 0;
   semaphore plate = 1;
   
   dad(){
   	while(1){
           准备一个苹果;
       	P(plate);
       	P(mutex);
       	把苹果放入盘子;
       	V(mutex);
       	V(apple);
       }
   }
   
   mom(){
       while(1){
           准备一个橘子;
       	P(plate);
       	P(mutex);
       	把橘子放入盘子;
       	V(mutex);
       	V(orange);
       }
   }
   
   daughter(){
       while(1){
           P(apple);
       	P(mutex);
           从盘中取出苹果;
           V(mutex);
           V(plate);
           吃苹果;
       }
   }
   
   son(){
       while(1){
           P(orange);
           P(mutex);
           从盘中取出橘子;
           V(mutex);
           V(plate);
           吃橘子;
       }
   }
   ```

3. 注：

   - 在多生产者多消费者中，如果缓冲区大小为1，那么<font color=red>有可能</font>不需要设置互斥信号量就可以实现互斥访问缓冲区的功能。
   - 不应该从“进程”的角度分析事件，应该从“事件”的角度来考虑。

### 六、吸烟者问题

1. 问题描述：假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但是要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草、第二个拥有纸、第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者进程一个信号告诉完成了，供应者就会放另外两种材料在桌上，这个过程一直重复。（让三个抽烟者轮流抽烟）

2. 实现：

   ```c
   semaphore offer1 = 0;
   semaphore offer2 = 0;
   semaphore offer3 = 0;
   semaphore finish = 0;
   int i = 0;
   
   provider(){
       while(1){
           for(i=0;i<3;i++){
               if(i%3==0){
                   将组合一放桌上;
                   V(offer1);
               }
               else if(i%3==1){
                   将组合二放桌上;
                   V(offer2);
               }
               else{
                   将组合三放桌上;
                   V(Offer3);
               }
           }
           p(finish);
       }
   }
   
   smoker1(){
       while(1){
           P(offer1);
           从桌上拿走组合一;
           卷烟;
           抽掉;
           V(finish);
       }
   }
   
   smoker2(){
       while(1){
           P(offer2);
           从桌上拿走组合二;
           卷烟;
           抽掉;
           V(finish);
       }
   }
   
   smoker3(){
       while(1){
           P(offer3);
           从桌上拿走组合三;
           卷烟;
           抽掉;
           V(finish);
       }
   }
   ```

### 七、读者──写者问题

1. 问题描述：有读者和写者两组并发进程，共享一个文件。当两个或两个以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：

   - 允许多个读者可以同时对文件执行读操作
   - 只允许一个写者往文件中写信息
   - 任一写者在完成写操作之前不允许其他读者或写者工作
   - 写者执行写操作前，应让已有的读者和写者全部退出

2. 实现：

   ```c
   semaphore rw = 1;       //用于实现对共享文件的互斥访问
   int count = 0;          //记录当前有几个读进程在访问文件
   semaphore mutex = 1;    //用于保证对count变量的互斥访问
   
   writer(){
       while(1){
           P(rw);        //写之前加锁
           写文件;
           V(rw);        //写完了解锁
       }
   }
   
   reader(){
       while(1){
           P(mutex);         //各进程互斥访问count
           if(count==0)      //由第一个读进程负责
               P(rw);        //读之前加锁
           count++;          //访问文件的进程数+1
           V(mutex);
           读文件;
           P(mutex);         //各进程互斥访问count
           count--;          //访问文件的进程数-1
           if(count==0)      //由最后一个读进程负责
               V(rw);        //读完了解锁
           V(mutex);
       }
   }
   ```

3. 注：

   - 只要有读进程还在读，写进程就要一直阻塞等待，可能“饿死”。<font color=orange>实际在这种情况下，读进程有更高的优先级</font>

   - 解决措施：读写公平法：

     ```c
     semaphore rw = 1;
     int count = 0;
     semaphore mutex = 1;
     semaphore w = 1;          //用于实现“写优先”
     
     writer(){
         while(1){
             P(w);
             P(rw);
             写文件;
             V(rw);
             V(w);
         }
     }
     
     reader(){
         while(1){
             P(w);
             P(mutex);
             if(count==0)
                 P(rw);
             count++;
             V(mutex);
             V(w);
             读文件;
             P(mutex);
             count--;
             if(count==0)
                 V(rw);
             V(mutex);
         }
     }
     ```

### 八、哲学家进餐问题

1. 问题描述：一张圆桌上坐着5名哲学家，每两个哲学家之间的桌上摆一根筷子，桌子的中间是一碗米饭。哲学家们倾注毕生的精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根拿起）。如果筷子已在他人手上，则需等待。

2. 实现：

   - 可以对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐。

     ```c
     semaphore chopstick[5] = {1,1,1,1,1};
     semaphore mutex = 4;
     
     Pi(){
         while(1){
             P(mutex);
             P(chopstick[i]);
             P(chopstick[(i+1)%5]);
             吃饭;
             V(chopstick[i]);
             V(chopstick[(i+1)%5]);
             V(mutex);
             思考;
         }
     }
     ```

   - 要求奇数号哲学家先拿左边的筷子，再拿右边的筷子，而偶数号哲学家刚好相反。

     ```c
     semaphore chopstick[5] = {1,1,1,1,1};
     
     Pi(){
         while(1){
     		if(i%2==1){
                 P(chopstick[i]);
             	P(chopstick[(i+1)%5]);
             }
             else{
                 P(chopstick[(i+1)%5]);
                 P(chopstick[i]);
             }
             吃饭;
             V(chopstick[i]);
             V(chopstick[(i+1)%5]);
             思考;
         }
     }
     ```

   - 当一名哲学家两边都有筷子时，才允许他拿起筷子。

     ```c
     semaphore chopstick[5] = {1,1,1,1,1};
     semaphore mutex = 1;
     
     Pi(){
         while(1){
             P(mutex);
             P(chopstick[i]);
             P(chopstick[(i+1)%5]);
             V(mutex);
             吃饭;
             V(chopstick[i]);
             V(chopstick[(i+1)%5]);
             思考;
         }
     }
     ```

### 九、管程

1. 管程的定义：

   - 概念：利用共享数据结构抽象地表示系统中的共享资源，而把对该数据结构实施的操作定义为一组过程，这个代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，叫做管程。
   - 组成：
     - 管程的名称
     - 局部于管程内部的共享结构数据说明
     - 对该数据结构进行操作的一组过程（函数）
     - 对局部于管程内部的共享数据设置初始值的语句
   - 特征：
     - 需要在管程中定义共享数据
     - 需要在管程中定义用于访问这些共享数据的“入口”，即函数
     - 只有通过这些特定的“入口”才能访问共享数据
     - 管程中有很多“入口”，但每次只能开放其中一个“入口”，并且只能让一个进程或线程进入在管程内部执行某个内部过程。
     - 可在管程中设置条件变量及等待/唤醒操作以解决同步问题。可以让一个进程或线程在条件变量上等待（此时，该进程应先释放管程的使用权，也就是让出“入口”）；可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。

2. 用管程解决生产者消费者问题：

   ```c++
   monitor ProducerConsumer
       condition full, empty;         //条件变量用来实现同步
       int count = 0;                 //缓冲区中的产品数
       void insert(Item item)         //把产品item放入缓冲区
       {
           if (count == N)
               wait(full);
           count++;
           insert_item(item);
           if (count == 1)
               signal(empty);
       }
   
       Item remove(Item item)         //从缓冲区中取出一个产品
       {
           if (count == 0)
               wait(empty);
           count--;
           if (count == N - 1)
               signal(full);
           return remove_item();
       }
   end monitor;
   
   producer(){
       while(1){
           item = 生产一个产品;
           ProducerConsumer.insert(item);
       }
   }
   
   consumer(){
       while(1){
           item = ProducerConsumer.remove();
           消费产品item;
       }
   }
   ```

## 四、死锁

### 一、死锁的概念

1. 定义：在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。

2. 死锁、饥饿、死循环的区别：

   - 死锁：各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。
   - 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。
   - 死循环：某进程执行过程中一直跳不出某个循环的现象。

   <table align="center">
   	<tr>
       	<th></th><th>共同点</th><th>区别</th>
       </tr>
       <tr>
           <td>死锁</td><td rowspan="3">都是进程无法顺利向前推进的现象</td><td>死锁一定是“循环等待对方手中的资源”导致的，因此如果有死锁现象，那<font color=red>至少有两个或两个以上的进程同时发生死锁。另外，发生死锁的进程一定处于阻塞态。</font></td>
       </tr>
       <tr>
           <td>饥饿</td><td><font color=red>可能只有一个进程发生饥饿。</font>发生饥饿的进程既可能时阻塞态，也可能时就绪态。</td>
       </tr>
       <tr>
       	<td>死循环</td><td>可能只有一个进程发生死循环。死循环的进程可以上处理机运行，只不过无法像期待的那样顺利推进。死锁和饥饿问题是由于操作系统分配资源的策略不合理导致的，而死循环是由代码逻辑的错误导致的。<font color=red>死锁和饥饿是管理者（操作系统）的问题，死循环是被管理者的问题。</font></td>
       </tr>
   </table>

3. 死锁产生的原因：

   - 死锁产生的必要条件：<font color=red>必须同时满足下列四个条件</font>
     - 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁。
     - 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。
     - 请求和保持条件：进程已经至少保持了至少一个资源，但又提除了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。
     - 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。
   - 对系统资源的竞争：各进程对不可剥夺的资源的竞争可能引起死锁。
   - 进程推进顺序非法

4. 死锁的处理策略：

   - 预防死锁：破坏死锁产生的四个必要条件中的一个或几个
   - 避免死锁：用某种方法防止系统进入不安全状态，从而避免死锁
   - 死锁的检测和解除：允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁

### 二、死锁预防

1. 破坏互斥条件：
   - 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁。
   - 方法：把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。
   - 举例：SPOOLing技术
   - 缺点：并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方还必须保护这种互斥性。因此，很多时候无法破坏互斥条件。
2. 破坏不剥夺条件：
   - 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。
   - 方法：
     - 当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。
     - 当某个进程需要的资源被其他进程所占有时，可以由操作系统协助，将想要的资源强行剥夺。
   - 缺点：
     - 实现起来比较复杂
     - 释放已获得的资源可能造成前一阶段工作的失效。
     - 反复地申请和释放资源会增加系统开销，降低系统吞吐量。
     - 若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都要放弃，以后再重新申请。如果一直发生这样的情况，就会导致饥饿。
3. 破坏请求和保持条件：
   - 请求和保持条件：进程已经至少保持了至少一个资源，但又提除了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。
   - 方法：采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归他所有，该进程就不会再请求别的任何资源了。
   - 优点：实现简单
   - 缺点：
     - 有些资源可能只需要用很短的时间，因此如果进程的整个运行期间一直保持著所有资源，就会造成严重的资源浪费，资源利用率极低。
     - 可能导致饥饿
4. 破坏循环等待条件：
   - 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。
   - 方法：采用顺序资源分配法，首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。
   - 缺点：
     - 不方便增加新的设备，因为可能需要重新分配所有编号
     - 进程实际使用资源的顺序可能和编号递增顺序不一致，会导致资源浪费
     - 必须按规定次序申请资源，用户编程麻烦

### 三、避免死锁

1. 系统安全状态：
   - 安全序列：如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。<font color=orange>（安全序列可能有多个）</font>
   - 不安全状态：如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。
   - 与死锁的联系：
     - 如果系统处于安全状态，就一定不会发生死锁
     - 如果系统进入不安全状态，就可能发生死锁
2. 银行家算法：
   - 算法思想：在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。
   - 数据结构：
     - 长度为m的一维数组Available：还有多少可用资源
     - n*m矩阵Max：各进程对资源的最大需求数
     - n*m矩阵Allocation：已经给各进程分配了多少资源
     - Max-Allocation=Need矩阵：各进程最多还需要多少资源
     - 长度为m的一维数组Request：进程此次申请的各种资源数
   - 算法步骤：
     - 检查此次申请是否超过了之前声明的最大需求数
     - 检查此时系统剩余的可用资源是否还能满足这次请求
     - 试探着分配，更改各数据结构
     - 用安全性算法检查此次分配是否会导致系统进入不安全状态
   - 安全性算法步骤：
     - 检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列，并把该进程持有的资源全部回收
     - 不断重复上述过程，看最终是否能让所有进程都加入安全序列

### 四、死锁的检测和解除

1. 死锁的检测：

   - 资源分配图：

     - 两种结点：
       - 进程结点：对应一个进程
       - 资源结点：对应一类资源，一类资源可能有多个
     - 两种边：
       - 进程结点──>资源结点：表示进程想申请几个资源
       - 资源结点──>进程结点：表示已经为进程分配了几个资源

     <img src="https://oliver-picture.oss-cn-beijing.aliyuncs.com/OS/ziyuan.png" alt="资源分配图" style="zoom:80%;" />

   - 算法：

     - 在资源分配图中，找出既不阻塞又不是孤点的进程Pi。消去它所有的请求边和分配边，使之成为孤立的结点。
     - 进程Pi所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。
     - 若进行一系列简化后，能消去图中所有的边，则称该图是可简化的。
     - 死锁定理：若某时刻系统的资源分配图是不可完全简化的，那么此时系统死锁。

2. 死锁的解除：

   - 资源剥夺法：挂起（暂时放到外存上）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。
   - 撤销进程法：强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。
   - 进程回退法：让一个或多个死锁进程回退到足以避免死锁的地步。

# 第三章：内存管理

## 一、内存管理概念

### 一、内存管理的基本原理和要求

1. 内存管理的功能：
   - 内存空间的分配与回收：
   - 地址转换：逻辑地址转换为物理地址
     - 绝对装入：编译时产生绝对地址
     - 可重定位装入：装入时将逻辑地址转换为物理地址
     - 动态运行时装入：运行时将逻辑地址转换为物理地址，需要设置重定位寄存器
   - 内存空间的扩充：
     - 覆盖技术
     - 交换技术
     - 虚拟内存技术
   - 存储保护：保证各进程在自己的内存空间内运行，不会越界访问。
     - 设置上下限寄存器，存放进程的上下限地址。进程的指令要访问某个地址时，CPU检查是否越界。
     - 采用重定位寄存器和界地址寄存器：
       - 重定位寄存器：存放进程起始物理地址
       - 界地址寄存器：存放进程的最大逻辑地址
2. 程序的装入和链接：
   - 编译：由编译程序将用户源代码编译程若干目标模块
   - 链接：由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块
     - 静态链接：在程序运行前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开
     - 装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式
     - 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的。便于修改和更新，便于实现对目标模块的共享
   - 装入：由装入程序将装入模块装入内存运行
     - 绝对装入：编译时产生绝对地址
     - 可重定位装入：装入时将逻辑地址转换为物理地址
     - 动态运行时装入：运行时将逻辑地址转换为物理地址，需要设置重定位寄存器
3. 逻辑地址空间与物理地址空间：
   - 逻辑地址空间：编译后，每个目标模块都是从0号单元开始编址，这称为该目标模块的相对地址（逻辑地址）。
   - 物理地址空间：内存中物理单元的集合，它是地址转换的最终地址。
   - 地址重定位：将逻辑地址转换为物理地址
4. 碎片：
   - 内部碎片：分配给某进程的内存区域中，没有被用上的部分
   - 外部碎片：内存中的某些空闲分区由于太小而难以利用
     - 可以通过紧凑技术来解决外部碎片（进程挪位，以合并出更大的内存空间）
5. 可重入代码（纯代码）：不能被修改的代码。

### 二、连续分配管理方式

1. 单一连续分配：
   - 内存被分为系统区和用户区
   - 特点：
     - 系统区通常处于内存的低地址部分，用于存放操作系统相关数据
     - 用户区用于存放用户进程相关数据，内存中<font color=red>只能有一道用户程序</font>，用户程序独占整个用户区空间
   - 优点：
     - 实现简单
     - 无外部碎片
     - 可以采用覆盖技术扩充内存
     - 不一定需要采取内存保护
   - 缺点：
     - 只能用于单用户、单任务的操作系统中
     - 有内部碎片
     - 存储器利用率极低
2. 固定分区分配：
   - 将整个用户空间划分为若干个固定大小的分区
   - 特点：
     - 在每个分区中直撞入一道作业
     - 操作系统建立一个数据结构──分区说明表，包含分区号、大小、起始地址、状态（是否已分配）
   - 分类：
     - 分区大小相等：缺乏灵活性，但很适合用于一台计算机控制多个相同对象的场合
     - 分区大小不等：增加了灵活性，可以满足不同大小的进程需求
   - 优点：
     - 实现简单
     - 无外部碎片
   - 缺点：
     - 当用户程序太大时，可能所有的分区都不能满足需求，不得不采用覆盖技术解决，会降低性能
     - 会产生内部碎片，内存利用率低
3.  动态分区分配：
   - 不会预先划分内存，而是在进程装入内存时，根据进程的大小动态地建立分区。
   - 系统要用什么样的数据结构记录内存的使用情况？
     - 空闲分区表：每一个空闲分区对应一个表项，表项中包含分区号、分区大小、起始地址、状态等信息
     - 空闲分区链：每个分区的起始部分和末尾部分分别设置前向和后向的指针。
   - 当有很多空闲分区都满足需求时，应该选择哪个分区进行分配？──动态分配算法
     - 首次适应算法（First Fit）：
       - 算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区
       - 实现方法：空闲分区以地址递增的次序排列。每次分配时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
       - 优点：综合看性能最好，算法开销小，回收分区后一般不需要对空闲分区队列重新排列。
     - 最佳适应算法（Best Fit）：
       - 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此尽可能保留大片的空闲区，优先使用更小的空闲区。
       - 实现方法：空闲分区以容量递增的次序排列。每次分配时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
       - 优点：会有更多的大分区被保留下来，更能满足大进程的需求。
       - 缺点：每次都选最小的分区进行分配，会留下越来越多、很小的、难以利用的内存块，产生很多外碎片
     - 最坏适应算法（Worst Fit）：
       - 算法思想：为了解决最佳适应算法留下太多外部碎片的问题，优先使用最大的连续区。
       - 实现方法：空闲分区以容量递减的次序排列。每次分配时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
       - 可以减少难以利用的外碎片
       - 缺点：每次都选最小=大的分区进行分配，会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有空间可以使用了
     - 邻近适应算法（Next Fit）：
       - 算法思想：每次都从上次查找结束的位置开始检索。
       - 实现方法：空闲分区以地址递增的次序排列（可排成一个循环链表）。每次分配时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
       - 优点：不用每次都从低地址的小分区开始检索，算法开销小。
       - 缺点：会使高地址的大分区也被用完。
   - 如何进行分区的分配与回收？──更新空闲分区表/空闲分区链

### 三、非连续分配管理方式

1. 基本分页存储管理方式：

   - 将内存空间分为一个个大小相等的分区，每个分区就是一个“页框”（页帧=内存快=物理块=物理页=实页=块）。每个页框都有一个编号，即“页框号”，页框号<font color=red>从0开始</font>。

   - 将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分称为一个“页面”（页=逻辑页=虚页）。每个页面页有一个编号，即“页号”，页号也是<font color=red>从0开始的</font>。

   - 操作系统<font color=red>以页框为单位为各个进程分配内存空间</font>。进程的每个页面分别放入一个页框中，<font color=red>进程的页面与内存的页框由一一对应的关系</font>。

   - 页表：

     - 为了能知道进程的每个页面在内存中存放的位置，操作系统要为每个进程建立一张页表
     - 一个进程对应一张页表
     - 进程的每个页面对应一个页表项
     - 每个页表项由“页号”和“块号”组成
     - 页表记录进程页面和实际存放的页框之间的映射关系
     - 每个页表项的长度是相同的

   - 每个页表项占多少字节？

     - 寻找内存块大小（内存块大小=页面大小）
     - 计算内存块数
     - 找寻内存块号的范围
     - 计算内存块号至少需要多少bit表示
     - 计算内存块号至少需要多少字节表示(xB)
     - 由于页号时隐含的，因此每个页表项占xB，存储整个页表至少需要x*nB

   - 如何实现地址的转换：（若要访问逻辑地址A）

     - 确定逻辑地址A对应的页号P
       $$
       页号=逻辑地址/页面长度
       $$
     
   - 找到P号页面在内存中的起始地址（查页表）
     
   - 确定逻辑地址A的“页内偏移量”W
       $$
       页内偏移量=逻辑地址\%页面长度
       $$
       
     - 逻辑地址A的物理地址=P号页面在内存中的起始地址+页内偏移量W

   - 页面大小取2的整数幂：
   
     - 逻辑地址的拆分更加迅速：如果每个页面大小为2^k B，用二进制表示逻辑地址，则末尾k位即为页内偏移量，其余部分就是页号。
     - 物理地址的计算更加迅速：根据逻辑地址得到页号，根据页号查询页表从而找到页面存放的存放号，将二进制表示的内存块号和页内偏移量拼接起来，就可以得到最终的物理地址
   
   - 逻辑地址结构：页号+页内偏移量
   
     - 如果由K位表示页内偏移量，则说明该系统中一个页面的大小是2^K个内存单元
     - 如果由M位表示页号，则说明在该系统中，一个进程最多允许有2^M个页面
   
   - 基本地址变换机构：
   
     - 页表寄存器（PTR）：存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的始址和页表长度放在进程控制块PCB中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。
     - 变换过程：
       - 根据逻辑地址计算页号P和页内偏移量W
       - 比较页号P和页表长度M，若P>=M，则产生越界中断，否则继续执行
       - 页表中的页号P对应的<font color=red>页表项地址=页表起始地址F+页号P*页表项长度</font>，取出该页表项内容b，即为内存块号。
         - 页表长度：页表中总共有几个页表项
         - 页表项长度：每个页表项占多大的存储空间
         - 页面大小：一个页面占多大的存储空间
       - 计算E=b*L+W，用得到的物理地址E去访存。
     - 为了页表的查询，常常会让一个页表项占更多的字节，使得每个页面恰好可以装下整数个页表项。
   
   - 具有快表的地址变换机构：
   
     - 快表（TLB）：联想寄存器，是一种访问速度比内存快很多的高速缓存，用来存放最近访问的页表项的副本，加速地址变换的速度。
     - 过程：
       - CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
       - 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，<font color=red>若快表命中，则访问某个逻辑地址仅需一次访存即可</font>。
       - 如果没有找到匹配的页号，则访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，<font color=red>若快表未命中，则访问某个逻辑地址需要两次访存</font>。
     - 若快表和慢表同时查询，则计算快表未命中时不需要加上查询快表的时间。
     - 局部性原理：
       - 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。
       - 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。
       - 基于此，一般快表命中率可达90%以上
   
   - 两级页表：
   
     - 单级页表的问题：
       - 页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。
       - 没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。
     - 两级页表的原理和地址结构：
       - 将原本长长的页表分为两部分，新建页目录表（外层页表/顶级页表）
       - 地址分为三部分：一级页号、二级页号和页内偏移量
     - 地址变换：
       - 按照地址结构将逻辑地址拆分成三部分
       - 从PCB中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中存放位置
       - 根据二级页号查表，找到最终想访问的内存块号
       - 结合页内偏移量的到物理地址
     - 注：
       - 若采用多级页表机制，<font color=red>各级页表的大小不能超过一个页面</font>
       - x级页表访存次数需要x+1次（没有快表机构）
   
2. 基本分段存储管理方式：

   - 思想：按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名，每段从0开始编址。
   - 内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以相互不相邻。
   - 逻辑地址结构：段号（段名）+段内地址（段内偏移量）
     - 段号的位数决定了每个进程最多可以分几个段
     - 段内地址位数决定了每个段的最大长度是多少
   - 段表：
     - 每个段对应一个段表项， 其中记录了该段在内存中的段号、起始位置（基址）和段的长度
     - <font color=red>各个段表项的长度是相同的</font>。为最大段长二进制位数+物理内存二进制位数。
   - 基本地址变换机构：
     - 根据逻辑地址得到段号S和段内地址W
     - 比较段号S和段表长度M，若S>=M，则产生越界中断，否则继续执行
     - 查询段表，找到对应的段表项，段表项的存放地址为F+S*段表项长度
     - 检查段内地址是否超过段长。<font color=red>若W>=C，则产生越界中断</font>，否则继续执行
     - 段表中的段号S对应的<font color=red>段表项地址=段表基址b+段内地址</font>

3. 分页与分段的区别：

   |                      |                         分页存储                         |                           分段存储                           |
   | :------------------: | :------------------------------------------------------: | :----------------------------------------------------------: |
   |         单位         |        页是信息的<font color=red>物理</font>单位         |          段是信息的<font color=red>逻辑</font>单位           |
   |         目的         |               实现离散分配，提高内存利用率               |                      更好地满足用户需求                      |
   |    是否对用户可见    |                          不可见                          |                             可见                             |
   |         大小         |                     固定且由系统决定                     |                 不固定，取决于用户编写的程序                 |
   |       地址空间       |         一维，只需给出一个记忆符即可表示一个地址         |             二维，既要给出段名，又要给出段内地址             |
   |   信息的共享和保护   |        略劣（分页可能会吧同种功能的指令分割开来）        |                             更优                             |
   | 访问地址需要几次访存 |                           2次                            |                             2次                              |
   |         优点         | 内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片 |            很方便按照逻辑模块实现信息的共享和保护            |
   |         缺点         |          不方便按照逻辑模块实现信息的共享和保护          | 如果段长过大，为其分配很大的连续空间会很不方便，另外，段式管理会产生外部碎片 |

4. 段页式管理方式：

   - 思想：将进程按逻辑模块分段，再将各段分页，再将内存空间分为大小相同的内存快
   - 逻辑地址结构：段号+页号+页内地址（页内偏移量）组成
     - 段号的位数决定了每个进程最多可以分多少段
     - 页号位数决定了每个段最大有多少页
     - 页内偏移量决定了页面大小、内存块大小是多少
   - 段表、页表
     - 每个段对应一个段表项，每个段表项由段号、页表长度、页表存放块号（页表起始地址）组成。每个<font color=red>段表项长度相等，段号是隐含的</font>
     - 每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号是隐含的
   - 基本地址变换：
     - 根据逻辑地址得到段号S、页号P、页内偏移量W
     - 比较段号S和段表长度M，若S>=M，则产生越界中断，否则继续执行
     - 查询段表，找到对应的段表项，段表项的存放地址为F+S*段表项长度
     - 检查页号P是否超过页表长度。<font color=red>若P>=页表长度，则产生越界中断</font>，否则继续执行
     - 根据页表存放块号、页号查询页表，找到对应页表项
     - 根据内存块号、页内偏移量得到最终的物理地址

## 二、虚拟内存管理

### 一、虚拟内存的基本概念

1. 传统存储管理方式：
   - 特征：
     - 一次性：作业必须一次性全部装入内存后才能开始运行
     - 驻留性：一旦作业被装入内存，就会一直驻留在内存中，知道作业运行结束
   - 缺点：
     - 作业很大时，不能全部装入内存，导致大作业无法运行
     - 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降
     - 内存中会驻留大量的、暂时用不到的数据，导致内存资源的浪费
2. 虚拟内存：
   - 定义：
     - 基于局部性原理，在程序装入时，可以将程序中<font color=red>很快会用到的部分装入内存，暂时用不到的部分留在外存</font>，就可以让程序开始执行。
     - 在程序执行过程中，当所访问的<font color=red>信息不在内存时</font>，由<font color=red>操作系统负责将所需信息从外存调入内存</font>，然后继续执行程序。
     - 若内存空间不够，由操作系统负责将内存中<font color=red>暂时用不到的信息换出到外存</font>。
     - 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。
   - 特征：
     - 多次性：无须再作业运行时一次性全部装入内存，而是允许被分成多次调入内存。
     - 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过城中，将作业换入、换出。
     - 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。
   - 实现方式：
     - 请求分页存储管理
     - 请求分段存储管理
     - 请求段页式存储管理
   - 与传统非连续分配存储管理的区别：
     - 操作系统要提供请求调页（或请求调段）功能
     - 操作系统要提供页面置换（或段置换）的功能

### 二、请求分页管理方式

1. 页表机制：页号+内存块号+状态位+访问字段+修改位+外存地址

   - 状态位：是否已调入内存
   - 访问字段：可记录最近被访问过几次，或记录上次访问的时间，供置换算法选择换出页面时参考
   - 修改位：页面调入内存后是否被修改过
   - 外存地址：页面在外存中的存放位置

2. 缺页中断机构：

   - 请求分页系统中，每当访问的页面不在内存时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断。此时<font color=red>缺页的进程阻塞</font>，放入阻塞队列，调页完成后再将其唤醒，放入就绪队列。
   - 如果内存中有空闲块，则为进程分配一个空闲块，将所却页面装入该块，并修改页表中相应的页表项。
   - 如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间<font color=red>被修改过</font>，则要将其<font color=red>写回外存</font>。未修改过的页面不用写回外存
   - <font color=red>缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断。</font><font color=orange>（故障）</font>

3. 地址变换机构：

   - 流程图：

     ![请求分页地址变换](https://oliver-picture.oss-cn-beijing.aliyuncs.com/OS/fenye.png)

   - 注：

     - 快表中有的页面一定是在内存中的。若某个页面被换出外存，则快表中的相应表项也要删除。
     - 只有“写指令”才需要修改“修改位”。并且，一般来说<font color=red>只需修改快表中的数据，只有要将快表项删除时才需要写回内存中的慢表</font>。这样可以减少访问次数。
     - 和普通的中断处理一样，缺页中断处理依然需要保留CPU现场。
     - 需要用某种“页面置换算法”来决定一个换出页面
     - 换入/换出页面都需要启动慢速的I/O操作，如果操作太频繁，会有很大的开销
     - 页面调入内存后，需要修改慢表，同时也需要将表项复制到快表中。

### 三、页面置换算法

1. 最佳置换算法（OPT）：

   - 思想：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面
   - 注：实际上最佳置换算法时无法实现的

2. 先进先出置换算法（FIFO）：

   - 思想：每次选择淘汰的页面是最早进入内存的页面
   - 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。<font color=orange>（队列的最大长度取决于系统为进程分配了多少个内存块）</font>
   - 优点：实现简单
   - 缺点：
     - 因为先进入的页面也有可能最经常被访问，因此算法性能差
     - 会产生Belady异常：当为进程分配的物理块数增大时，缺页次数不减反增的异常现象

3. 最近最久未使用置换算法（LRU）：

   - 思想：每次淘汰的页面时最近最久未使用的页面
   - 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t，当需要淘汰一个页面时，选择现有页面中t值最大的。
   - 优点：算法性能好
   - 缺点：需要专门的硬件支持，实现困难，开销大

4. 时钟置换算法（CLOCK）：

   - 简单的时钟淘汰算法（CLOCK）：

     - 实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1.当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面。<font color=orange>（最多会经过两轮扫描）</font>
     - 优点：实现简单，算法开销小
     - 缺点：仅考虑到页面是否被访问过，没有考虑是否被修改过

   - 改进的时钟淘汰算法──最近未用算法（NRU）：

     - 实现方法：用（访问位，修改位）一起判断页面状态。将所有可能被置换的页面排成一个循环队列，执行下列操作：

       - 第一轮：从当前位置开始扫描第一个(0,0)的帧用于替换。本轮扫描不修改任何标志位。
       - 第二轮：若第一轮扫描失败，则重新扫描，查找第一个(0,1)的帧用于替换。本轮将所有扫描过的帧访问位设为0.
       - 第三轮：若第二轮扫描失败，则重新扫描，查找第一个(0,0)的帧用于替换。本轮扫描不修改任何标志位。
       - 第四轮：若第三轮扫描失败，则重新扫描，查找第一个(0,1)的帧用于替换。

       <font color=orange>最多会进行四轮扫描</font>

     - 优点：

       - 算法开销小
       - 性能不错

### 四、页面分配策略

1. 驻留集：
   - 定义：指请求分页存储管理中给进程分配的物理块的集合。
   - 考虑问题：
     - 分配给一个进程的存储量越小，任何时候驻留在主存的进程数就越多，从而可以提高处理机的时间利用效率。
     - 若一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然会相对较高。
     - 若页数过多，根据局部性原理，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响。
2. 置换策略：
   - 固定分配：操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。<font color=orange>（即驻留集大小不变）</font>
   - 可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。<font color=orange>（即驻留集大小可变）</font>
   - 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将<font color=red>别的进程持有的物理块</font>置换到外存，再分配给缺页进程。
   - 局部置换：发生缺页时只能选<font color=red>进程自己的物理块进行置换</font>
3. 三种常用策略：
   - 固定分配局部置换：
     - 思想：系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行过程中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。
     - 缺点：很难在刚开始就确定应为每个进程分配多少个物理块才合理。
   - 可变分配全局策略：
     - 思想：刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程；若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将给物理块分配给缺页的进程。
     - <font color=red>只要某进程发生缺页都将获得新的物理块</font>
     - 被选择调出的页可能时是系统中任何一个进程中的页，因此这个<font color=red>被选中的进程拥有的物理块会减少，缺页率会增加</font>
   - 可变分配局部策略：
     - 刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度；反之，如果进程在运行中缺页率特别低，则可适当减少分配给进程的物理块。
4. 何时调入页面：
   - 预调页策略：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。但如果提前调入的页面中大多数都没被访问过，则又是低效的。因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。故这种策略主要用于<font color=red>进程的首次调入</font>，由程序员指出应该先调入哪些部分。
   - 请求调页策略：进程<font color=red>在运行期间发现缺页时才将所缺页面调入内存</font>。I/O开销较大。
5. 何处调入页面：
   - 系统拥有足够的对换区空间：页面的调入、调出都是在内存与对换区之间进行
   - 系统缺少足够的对换区空间：凡是不会被修改的数据都是直接从文件区调入。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。
   - UNIX方式：运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。

### 五、抖动

1. 定义：刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的行为叫抖动，也称颠簸。
2. 主要原因：进程频繁访问的页面数目高于可用的物理块数。

### 六、工作集

1. 定义：进程在某段时间间隔内，进程实际访问页面的集合。
2. 操作系统会根据“窗口尺寸”算出工作集。
3. 工作集大小可能小于窗口尺寸，实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块。
4. 基于局部性原理，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的。因此，可以根据进程近期访问的页面集合（工作集）来设计一种页面置换算法：选择一个不在工作集中的页面进行淘汰

# 第四章：文件管理

## 一、文件系统基础

1. 
